{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission to Mars\n",
    "\n",
    "### Web-Scraping for Mars Info\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that initializes browser\n",
    "def init_browser():\n",
    "    # Initialize browser using chromedriver\n",
    "    executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "    \n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that visits a website and scrapes the html into Beautiful Soup\n",
    "def get_html(url):    \n",
    "    \n",
    "    # visit website\n",
    "    browser.visit(url)\n",
    "\n",
    "    # scrape page into soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"lxml\")\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Initialize browser using chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize browser using chromedriver\n",
    "browser = init_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### NASA Mars News\n",
    "\n",
    "* Get title and teaser paragraph for latest Mars news story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set url and scrape site into soup\n",
    "NASA_url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+'\\\n",
    "        'desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "\n",
    "soup = get_html(NASA_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NASA Invites Students to Name Mars 2020 Rover\n",
      "P: Through Nov. 1, K-12 students in the U.S. are encouraged to enter an essay contest to name NASA's next Mars rover.\n"
     ]
    }
   ],
   "source": [
    "# get html for latest news story\n",
    "latest_story = soup.find('li', attrs={'class': 'slide'})\n",
    "\n",
    "# get title and paragraph from latest story (first story)\n",
    "news_title = latest_story.find('div', {'class': 'content_title'}).text\n",
    "print(f\"Title: {news_title}\")\n",
    "\n",
    "news_p = latest_story.find('div', {'class': 'article_teaser_body'}).text\n",
    "print(f\"P: {news_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### JPL Mars Space Images\n",
    "\n",
    "- Get url for featured Mars image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set url and scrape site into soup\n",
    "JPL_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "\n",
    "soup = get_html(JPL_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featured_image_url:\n",
      "https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA17200_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "# find url for image\n",
    "relative_url = soup.find('a', id='full_image')['data-fancybox-href']\n",
    "\n",
    "JPL_base_url = 'https://www.jpl.nasa.gov'\n",
    "\n",
    "featured_image_url = JPL_base_url + relative_url\n",
    "print(f\"featured_image_url:\\n{featured_image_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Mars Weather\n",
    "\n",
    "- Get latest tweet from Mars Weather Twitter account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set url and scrape site into soup\n",
    "weather_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "\n",
    "soup = get_html(weather_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We won’t be hearing from @MarsCuriosity or @NASAInSight for the next 2 weeks during Mars solar conjunction. Read more about why Mars missions go silent every 2 years: https://www.wral.com/mars-spacecraft-go-quiet-during-solar-conjunction/18595551/ …pic.twitter.com/fWruE2v151\n"
     ]
    }
   ],
   "source": [
    "# save text of latest tweet\n",
    "mars_weather = soup.find('p', {'class': 'TweetTextSize'}).text.replace('\\n', ', ')\n",
    "print(mars_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Mars Facts\n",
    "\n",
    "- Visit the Mars Facts webpage here and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "- Use Pandas to convert the data to a HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <tbody>\\n    <tr>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <td>Mass:</td>\\n      <td>6.39 × 10^23 kg (0.11 Earths)</td>\\n    </tr>\\n    <tr>\\n      <td>Moons:</td>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.38 AU)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <td>Surface Temperature:</td>\\n      <td>-87 to -5 °C</td>\\n    </tr>\\n    <tr>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set url\n",
    "facts_url = 'https://space-facts.com/mars/'\n",
    "\n",
    "# read tables into pandas\n",
    "tables = pd.read_html(facts_url)\n",
    "\n",
    "# get relevant table\n",
    "df = tables[1]\n",
    "\n",
    "# convert df to html table string; remove index and col headings; set CSS id\n",
    "html_table = df.to_html(index=False, header=False, table_id='mars-table', classes=['table', 'table-striped'])\n",
    "\n",
    "html_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Mars Hemispheres\n",
    "\n",
    "* Visit the USGS Astrogeology site (https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "* You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "* Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "\n",
    "* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set url for USGS Astrogeology site and visit\n",
    "USGS_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "# names of hemispheres\n",
    "hemi_names = [\n",
    "    'Cerberus Hemisphere',\n",
    "    'Schiaparelli Hemisphere',\n",
    "    'Valles Marineris Hemisphere',\n",
    "    'Syrtis Major Hemisphere'\n",
    "]\n",
    "\n",
    "# visit USGS website\n",
    "browser.visit(USGS_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'},\n",
       " {'title': 'Valles Marineris Hemisphere',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere',\n",
       "  'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up empty list for img url dicts\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# loop through hemispheres, get img urls after clicking links\n",
    "for hemi in hemi_names:\n",
    "\n",
    "    # click link for hemisphere\n",
    "    browser.click_link_by_partial_text(hemi)\n",
    "\n",
    "    # get html with bs4\n",
    "    soup = bs(browser.html, \"lxml\")\n",
    "\n",
    "    # find image url in first anchor of first list item on page\n",
    "    img_url = soup.find('li').find('a')['href']\n",
    "\n",
    "    # create dict for image and add to list\n",
    "    hemi_dict = dict(title=hemi, img_url=img_url)\n",
    "    hemisphere_image_urls.append(hemi_dict)\n",
    "    \n",
    "    # redirect back\n",
    "    browser.back()\n",
    "    \n",
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Close browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close browser\n",
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
